[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Schuller",
    "section": "",
    "text": "A set of notes for Frederic Schuller’s course on Mathematical Physics for the Heraeus International School on Gravity and Light."
  },
  {
    "objectID": "Lecture3.html",
    "href": "Lecture3.html",
    "title": "1  Multilinear Algebra",
    "section": "",
    "text": "Traditionally, this subsect is known as Tensor Theory.\nMultilinear algebra is the same field as the more familiar Linear Algebra- the only difference is we extend our mappings of consideration from linear maps to so called multilinear maps. The object of study of multilinear algebra is just vector spaces.\nIt is beneficial to first study Vector Spaces in full (abstract) detail before moving on for two reasons:"
  },
  {
    "objectID": "Lecture3.html#vector-spaces",
    "href": "Lecture3.html#vector-spaces",
    "title": "1  Multilinear Algebra",
    "section": "1.1 Vector Spaces",
    "text": "1.1 Vector Spaces\nDefinition: An \\mathbb{R} Vector Space (V, +, *) is\n\nA set V\n+:V\\times V\\to V (vector addition)\n*:\\mathbb{R}\\times V \\to V (scalar multiplication)\n\nwhich satisfies the following rules:\n\n\nv + w = w + v for v,w \\in V\n\n\n(u + v) + w = u + (v + w) for u,v,w \\in V\n\n\n\\exists 0\\in V such that \\forall v \\in V: v + 0 = v\n\n\n\\forall v \\in V, \\exists (-v) \\in V: v + (-v) = 0\n\n\n\\lambda \\cdot (\\nu \\cdot v) = (\\lambda \\cdot \\nu) \\cdot v \\forall \\lambda, \\nu \\in \\mathbb{R} and \\forall v \\in V.\n\n\n(\\lambda + \\nu)v = \\lambda v + \\nu v\n\n\n\\lambda \\nu + \\lambda w = \\lambda(v+w)\n\n\n1\\cdot v = v\n\n\nSummary: Any structure of this type that satisfies these axioms is a vector space.\nTerminology: An element of a vector space is often referred to (informally) as a vector.2.2 You must not ask the question: What is a vector?. You couldn’t tell that an object is a vector just by looking at it. You need to check how it behaves with other similar objects.\n\n1.1.1 Example\nConsider the set of polynomials P_n := \\{p=\\sum_{i=0}^{n}p_ix^i\\} with p_i\\in \\mathbb{R} and p:(-1,1)\\to\\mathbb{R}. At this stage, we may ask the simple question: is \\square:x\\mapsto x^2 a vector? NO! \\square is an element of the set P. We have not defined a vector space for which addition and s-multiplication make sense.\nNow, we define +:P\\times P \\to P whereby (p,q) \\mapsto p+q defined by\n(p+q)(x) = p(x) + q(x).\nSimilarly, we may define s-multiplication \\cdot: \\mathbb{R}\\times P \\to P whereby\n (\\lambda \\cdot p)(x) = \\lambda \\cdot p(x) \nNow that we have defined the structure, we could decide that \\square is an element of our vector space (P, +, \\cdot). Of course, we should formamly prove that (P, +, \\cdot** does satisfy the axioms of a vector space…"
  },
  {
    "objectID": "Lecture3.html#linear-maps",
    "href": "Lecture3.html#linear-maps",
    "title": "1  Multilinear Algebra",
    "section": "1.2 Linear Maps",
    "text": "1.2 Linear Maps\nThese are the structure-respecting maps between vector spaces:\nDefinition If (V, +_v, \\cdot_v) and (W, +_w, \\cdot_w) are vector spaces. Then a map \\phi:V\\to W is called linear if:\n\n\\phi(v+_v\\tilde{v}) = \\phi(v) +_w \\phi(\\tilde v)\n\\phi(\\lambda \\cdot_v v) = \\lambda \\cdot_w \\phi(v)\n\n\n1.2.1 Example (Differentiation)\nConsider \\delta:P \\to P3 whereby3 Notation: we write \\phi: V \\xrightarrow{\\sim} W to denote a linear map.\n p\\mapsto \\delta(p) := p'\ndefines the differentiation.\n\nLinearity: \\delta(p+q) = (p+q)' = p'+q' = \\delta(p) + \\delta(q)\nMultiplication: \\delta(\\lambda p) = (\\lambda p)' = \\lambda p' = \\lambda \\delta(p)\n\nTheorem If \\phi:V \\xrightarrow{\\sim} and \\psi:W \\xrightarrow{\\sim} W, then \\psi \\circ \\phi : V \\xrightarrow{\\sim} U\n\n\n1.2.2 Example\n\\delta \\circ \\delta: P \\xrightarrow{\\sim} P is linear."
  },
  {
    "objectID": "Lecture3.html#vector-space-of-homomorphisms",
    "href": "Lecture3.html#vector-space-of-homomorphisms",
    "title": "1  Multilinear Algebra",
    "section": "1.3 Vector Space of Homomorphisms",
    "text": "1.3 Vector Space of Homomorphisms\nFun-fact: If (V, +, \\cdot), (W, +, \\cdot) are vector spaces, then we can define the set\n\\text{Hom}(V,W) := \\{ \\phi: V \\xrightarrow{\\sim} W\\}\nWe can make this into a vector space by\n\n+: \\text{Hom}(V,W) \\times \\text{Hom}(V,W) \\to \\text{Hom}(V,W) whereby  (\\phi, \\psi) \\mapsto \\phi + \\psi  so that (\\phi + \\psi)(v) := \\phi(v) + \\psi(v) \n… and the same for s-multiplication\n\n\n1.3.1 Example \\text{Hom}(P,P)\nis a vector space. This means that \\delta \\in \\text{Hom}(P,P), \\delta \\circ \\delta \\in \\text{Hom}(P, P), and so on until \\delta^{(m)} \\in \\text{Hom}(P,P)"
  },
  {
    "objectID": "Lecture3.html#dual-vector-space",
    "href": "Lecture3.html#dual-vector-space",
    "title": "1  Multilinear Algebra",
    "section": "1.4 Dual Vector Space",
    "text": "1.4 Dual Vector Space\nThis is just a heavily used special case…\nDefinition: V^* := \\{\\phi:V\\xrightarrow{\\sim} \\mathbb{R}\\} = \\text{Hom}(V, \\mathbb{R}) is the set of linear maps on V. We say that (V^*, +, \\cdot) is the dual vector space to V.\nTerminology: We call \\phi \\in V^* a covector.\n\n1.4.1 Example\nConsider the map I:P\\xrightarrow{\\sim}\\mathbb{R}, i.e. I\\in P^* defined such that4 \\begin{equation}\n    I(p) := \\int_0^1 dx \\; p(x)\n\\end{equation}4 This is exactly how we think of the “bras” working in quantum mechanics!"
  },
  {
    "objectID": "Lecture3.html#tensors",
    "href": "Lecture3.html#tensors",
    "title": "1  Multilinear Algebra",
    "section": "1.5 Tensors",
    "text": "1.5 Tensors\nDefinition: Let (V, +, \\cdot) a vector space. Then, an (r,s)-Tensor over V is a multilinear map \\begin{equation}\n    T: V^*\\times \\underset{r}{...} \\times V^* \\times V\\times \\underset{s}{...} \\times V \\xrightarrow{\\sim} \\mathbb{R}\n\\end{equation}\n\n1.5.1 Example\nLet T be a (1,1)-tensor. Then \\begin{align}\n    T(\\phi, + \\psi, v) &= T(\\phi, v) + T(\\psi, v) \\\\\n    T(\\lambda\\phi, v) &= \\lambda T(\\phi, v) \\\\\n    T(\\phi, v+w) &= T(\\phi, v) + T(\\phi, w) \\\\\n    T(\\phi, \\lambda v) &= \\lambda T(\\phi, v)\n\\end{align}\nWhat is T(\\phi + \\psi, v + w)? Use linearity twice: \\begin{equation}\n    T(\\phi + \\psi, v + w) = T(\\phi, v) + T(\\phi, w) + T(\\psi, v) + T(\\psi, w)\n\\end{equation}\n\n\n1.5.2 Excursion\nLet T: V^* \\times V \\xrightarrow{\\sim} \\mathbb{R}, then we may define the map 5 \\begin{align}\n    \\phi_T&: V \\xrightarrow{\\sim} (V^*)^*\\\\\n    v&\\mapsto T(\\cdot, v)\n\\end{align}5 It is a fact that for finite dimensional vector spaces V, (V^*)^*=V.\nGiven a map \\phi: V\\xrightarrow{\\sim} V, we can construct the map \\begin{align}\n    T_\\phi &: V^*\\times V \\xrightarrow{\\sim} \\mathbb{R} \\\\\n    (\\varphi, v) &\\mapsto \\varphi(\\phi(v))\n\\end{align}\nIt follows that T = T_{\\phi_T} and \\phi = \\phi_{T_\\phi}\nIn other words, a map from V to V contains the same data as a map from (V^*\\times V) to \\mathbb{R}.\n\n\n1.5.3 Example\nConsider: g: P\\times P \\xrightarrow{\\sim} \\mathbb{R} such that \\begin{equation}\n    (p,q) \\mapsto \\int_{-1}^1 dx\\; p(x)q(x)\n\\end{equation} is a (0,2)-tensor over P.\nIn other words, inner products are tensors…"
  },
  {
    "objectID": "Lecture3.html#vectors-and-covectors-as-tensors",
    "href": "Lecture3.html#vectors-and-covectors-as-tensors",
    "title": "1  Multilinear Algebra",
    "section": "1.6 Vectors and Covectors as Tensors",
    "text": "1.6 Vectors and Covectors as Tensors\nTheorem: \\begin{equation}\n    \\phi \\in V^* \\iff \\phi: V\\xrightarrow{\\sim}\\mathbb{R} \\iff \\phi \\text{ is a } (0,1)\\text{-tensor}\n\\end{equation}\nTheorem: \\begin{equation}\n    v\\in V=(V^*)^* \\iff v:V^* \\xrightarrow{\\sim} \\mathbb{R} \\iff v \\text{ is a } (1,0)\\text{-tensor}\n\\end{equation}\nOkay, good! We are safe using tensors for everything."
  },
  {
    "objectID": "Lecture3.html#bases",
    "href": "Lecture3.html#bases",
    "title": "1  Multilinear Algebra",
    "section": "1.7 Bases",
    "text": "1.7 Bases\nDefinition: Let (V, +, \\cdot) be a vector space. A subset B \\subset V is called a basis6 if \\forall v\\in V, \\exists ! finite F\\subset B such that \\exists ! v^1,...,v^n \\in \\mathbb{R} so that \\begin{equation}\nv = v^1f_1 + ... + v^n f_n\n\\end{equation}6 Specifically, a Hamel basis. link\nOr in words: for each vector there exists a unique subset of B such that there exists a unique finite collection of real numbers v^i so that v=v^if_i.\nDefinition: If there exists a basis B\\subset V with finitely many elements, say, d-many, then we call d the dimension of the vector space.\nRemark: Let V be a finite dimensional vector space. Having chosen a basis e_1, ..., e_n of V, we may uniquely associate \\begin{equation}\n    v \\mapsto (v^1, ..., v^n)\n\\end{equation}\ncalled the components of v with respect to the chosen bases e_1,...,e_n, where\n\\begin{equation}\n    v = v^1e_1 + ... + v^n e_n\n\\end{equation}"
  },
  {
    "objectID": "Lecture3.html#basis-for-the-dual-space",
    "href": "Lecture3.html#basis-for-the-dual-space",
    "title": "1  Multilinear Algebra",
    "section": "1.8 Basis for the Dual Space",
    "text": "1.8 Basis for the Dual Space\nGiven an choice of basis e_1, ..., e_n for V, you can choose a basis \\epsilon^1,...\\epsilon^n for V^*. It is economical to require that once a basis e_j has been chosen on V, then \\begin{equation}\n    \\epsilon^i(e_j) = \\delta_j^i\n\\end{equation} uniquely determines the basis \\epsilon^i for the dual space.77 We call such a basis the dual basis of the dual space.\n\n1.8.1 Example\nConsider P_3 with basis e_0, e_1, e_2, e_3 so that \\begin{align}\n    e_0(x) &= 1 \\\\\n    e_1(x) &= x \\\\\n    e_2(x) &= x^2 \\\\\n    e_3(x) &= x^3\n\\end{align}\nThe dual basis \\epsilon^0, \\epsilon^1, \\epsilon^2, \\epsilon^3 is given by \\begin{equation}\n    \\epsilon^a := \\frac{1}{a!}\\partial^a\\Big\\vert_{x=0}\n\\end{equation}"
  },
  {
    "objectID": "Lecture3.html#components-of-tensors",
    "href": "Lecture3.html#components-of-tensors",
    "title": "1  Multilinear Algebra",
    "section": "1.9 Components of Tensors",
    "text": "1.9 Components of Tensors\nDefinition: Let T be an (r,s)-tensor over a finite-dimensional vector space V with basis e_1,...e_n. Then define the (r+s)^{\\text{dim}(V)} many real numbers \\begin{equation}\n    T^{i_1,...,i_r}_{j_1,...,j_s} = T(\\epsilon^{i_1},...\\epsilon^{i_r},e_{j_1}, ..., e_{j_s})\n\\end{equation} where \\epsilon^i is the dual basis for V.\nThese numbers are called the components of the tensor with respect to the chosen basis.\nThis is useful because knowing the components (and the basis from which they came) allows us to reconstruct the entire tensor.\n\n1.9.1 Example\nSay T is a (1,1)-tensor. Then it’s components are \\begin{equation}\n    T^i_j := T(\\epsilon^i, e_j)\n\\end{equation}\nTo reconstruct T from these components, we have \\begin{align}\nT(\\phi, v) &= T\\left(\\sum_i \\phi_i\\epsilon^i, \\sum_j v^je_j \\right) \\\\\n    & = \\sum_i\\sum_j \\phi_iv^j T(\\epsilon^i, e_j) \\\\\n    &= \\sum_i\\sum_j \\phi_iv^jT^i_j\n\\end{align}88 Going forward, we will use the Einstein sumation convention which means T(\\phi, v) = \\phi_iv^jT^i_j, i.e. any index that is repeated with one up and one down implieas a sum."
  },
  {
    "objectID": "Lecture4.html",
    "href": "Lecture4.html",
    "title": "2  Differentiable Manifolds",
    "section": "",
    "text": "We are now considering differentiable manifolds. So far, we looked at topological manifolds which, roughly speaking, we would like to extend to allow us to define a velocity to each point on a curve. Is the structure (\\mathcal{M}, \\mathcal{O}) enough to talk about differentiability of curves? No! We need to make more choices (i.e. add more structure) before we can discuss differentiablility of a curve.\nWe wish to define a notion of differentiable… \\begin{align}\n\\gamma &:\\mathbb{R} \\to \\mathcal{M} \\text{  (curves)  } \\\\\nf&:\\mathcal{M} \\to \\mathbb{R} \\text{  (functions)  } \\\\\n\\phi &: \\mathcal{M} \\to \\mathcal{N} \\text{  (maps)  } \\\\\n\\end{align}"
  },
  {
    "objectID": "Lecture4.html#strategy",
    "href": "Lecture4.html#strategy",
    "title": "2  Differentiable Manifolds",
    "section": "2.1 Strategy",
    "text": "2.1 Strategy\nLet’s consider curves \\gamma: \\mathbb{R} \\to \\mathcal{M}. We don’t know what to do with this object on a manifold so what do we do? We consider the portion of the curve that lies in the chart domain of (U, x).\n\n\n\n\n\nFigure 2.1: mapping diagram\n\n\nThe idea is to try to lift the undergraduate notion of differentiability of the curve on \\mathbb{R}^d (i.e. of x\\circ\\gamma) to a notion of differentiability of the curve on the manifold \\mathcal{M} (i.e. of \\gamma itself**.\n\n\n\n\n\nFigure 2.2: overlapping charts\n\n\nProblem: How do we make this well defined under change of chart? In other words, in Figure 2.2 does differentiability of x\\circ\\gamma guarantee differentiability of y\\circ\\gamma?\nFrom Figure 2.2, we see that \\begin{align}\n    y \\circ \\gamma &= (y\\circ x^{-1}) \\circ (x \\circ \\gamma) \\\\\n    &= y \\circ (x^{-1} \\circ x) \\circ \\gamma\n\\end{align}\nWe already confirmed that x\\circ \\gamma is (undergraduate) differentiable as a function from \\mathbb{R}\\to\\mathbb{R}^d. Since we are working with topological manifolds and assuming that the chart transition maps are continuous, then the most we can say about y\\circ x^{-1} is that it is continuous. As we are composing a continuous map with a differentiable map, the answer is that y\\circ \\gamma is maybe differentiable.\nWhat is the remedy for this problem?"
  },
  {
    "objectID": "Lecture4.html#compatible-charts",
    "href": "Lecture4.html#compatible-charts",
    "title": "2  Differentiable Manifolds",
    "section": "2.2 Compatible Charts",
    "text": "2.2 Compatible Charts\nIn the previous section, we considered any imaginable charts (\\mathcal{U}, x) in our topological manifold (\\mathcal{M}, \\mathcal{O}).1 We have seen that this is not sufficient to enable differentiablility of curves, functions, and maps. Therefore, we seek to limit the set of allowed charts to only those charts whose transition maps are differentiable.1 To emphasise this, we may say that we took these charts (\\mathcal{U}, x) from the maximal Atlas \\mathscr{A} of (\\mathcal{M}, \\mathcal{O}).\nDefinition: Two charts (\\mathcal{U}, x) and (\\mathcal{V}, y) are called \\ast-compatible if either:\n\n\\mathcal{U}\\cap\\mathcal{V} = \\empty\n\\mathcal{U}\\cap\\mathcal{V} \\neq \\empty and the chart transition maps y\\circ x^{-1} and x \\circ y^{-1} are (undergraduate) \\ast.2\n\n2 Here we use \\ast as there are different types of compatibility we may care about. Here, we are specifically interested in differentiably compatible.Definition: An atlas \\mathscr{A}_{\\ast} is an \\ast-compatible atlas if for any two charts in \\mathscr{A}_{\\ast}, the charts are \\ast-compatible.\nFor physics this is a really down to Earth question. Am I choosing the right structure here?\n\n\n\n\n\n\n\n\n\\ast\nudergraduate - \\ast\ndescription\n\n\n\n\nC^0\nC^{0}:\\mathbb{R}^d\\to\\mathbb{R}^d\ncontinuous maps w.r.t. \\mathcal{O}_{st}\n\n\nC^{1}\nC^1:\\mathbb{R}^d \\to \\mathbb{R}^d\ndifferentiable (once) with continuous result\n\n\nC^k\n\\vdots\nk-times continuously differentiable 3\n\n\nD^k\n\\vdots\nk-times differentiable\n\n\nC^\\infty\n\\vdots\ninfinitely differentiable, aka smooth\n\n\nC^\\omega\n\\vdots\n\\exists a multidemnsional Taylor expansion\n\n\n\\mathbb{C}^\\infty\n\\vdots\nFor even dimensional manifold that are smooth and satisfy the generalized Cauchy-Riemann conditions 4\n\n\n\n3 Typically, C^k is more favored than D^k.4 Generally, the further down you go in this table, the more conditions you add and therebore more resitrictions you impose on your atlas \\mathscr{A}.The natural next question is: To what degree to derivatives appear in physics? It turns out we don’t need to worry!\nTheorem: (Whitney) Any C^k-atlas, \\mathscr{A}_{C^k} with k\\geq 1 contains a C^\\infty atlas.\nUpshot: If we have a C^k atlas, we can always keep tossing out charts until we are left with a C^\\infty atlas.55 Thus we may always consider smooth C^\\infty manifolds without loss of generality unless we wish to define Taylor Expandability, Complex Differentiability, …"
  },
  {
    "objectID": "Lecture4.html#diffeomorphisms",
    "href": "Lecture4.html#diffeomorphisms",
    "title": "2  Differentiable Manifolds",
    "section": "2.3 Diffeomorphisms",
    "text": "2.3 Diffeomorphisms\nConsider maps \\Phi:\\mathcal{M}\\to\\mathcal{N}\n\nIf M,N are naked sets, the structure preserving maps are the bijections (the invertible maps)\n\nA set M and N are called set-theoretically isomorphic, M\\cong N if there exists a bijection \\Phi between them.6\n\nIf we have topoologies (\\mathcal{M}, \\mathcal{O}_M), (\\mathcal{N}, \\mathcal{O}_N), the structure-preserving maps are the homeomorphisms (i.e. continuous bijections)\n\nIf this exists, then we call the two spaces topologically isomorphic (or homeomorphic)\n\nIf we have vector spaces U, V. Then the structure-preserving maps are again bijections that are both ways linear\nTwo C^\\infty manifolds (\\mathcal{M}, \\mathcal{O}_m, \\mathscr{A}_m) and (\\mathcal{N}, \\mathcal{O}_n, \\mathscr{A}_n) are said to be Diffeomorphic if a bijection, \\Phi exists and \\Phi and \\Phi^{-1} are both C^{\\infty} maps.7\n\n6 \\mathbb{N} \\cong \\mathbb{Z}, \\mathbb{N}\\cong \\mathbb{Q}, but \\mathbb{N}\\not{\\cong} \\mathbb{R}.7 As in Figure 2.3\n\n\n\nFigure 2.3: Differentiable Maps\n\n\n\nTheorem: The number of C^\\infty manifolds one can make out of a give C^0 manifold up to diffeomorphism\n\n\n\n\n\n\n\ndim \\mathcal{M}\n#\n\n\n\n\n1\n1\n\n\n2\n1\n\n\n3\n1\n\n\n4\ngenerically (in particular for non-compact manifolds): uncountably infinitely many\n\n\n\\vdots\n\\vdots\n\n\nd>4\nfinitely-many (via surgery-theory)"
  },
  {
    "objectID": "Lecture5.html",
    "href": "Lecture5.html",
    "title": "3  Tangent Spaces",
    "section": "",
    "text": "Lead Question: What is the velocity of a curve \\gamma at point p?"
  },
  {
    "objectID": "Lecture5.html#velocities",
    "href": "Lecture5.html#velocities",
    "title": "3  Tangent Spaces",
    "section": "3.1 Velocities",
    "text": "3.1 Velocities\nDefinition: Let (\\mathcal{M},\\mathcal{O},\\mathscr{A}) be a smooth manifold with a curve \\gamma:\\mathbb{R}\\to\\mathcal{M} at least C^1. Suppose that \\gamma(\\lambda_0) = p. The velocity of \\gamma at p is the linear map1 \\begin{align}\n   \\mathscr{v}_{\\gamma,p}&:C^{\\infty}(\\mathcal{M})\\xrightarrow{\\sim}\\mathbb{R} \\\\\n   f&\\mapsto \\mathscr{v}_{\\gamma, p}(f) := (f\\circ \\gamma)'(\\lambda_0)\n\\end{align}1 Your ill-definition alarm bells should be ringing. In the end, there should be no dependence on the choice of chart of we’ve done something wrong.\nLoose idea: The equivalence with what you’ve probably seen in the past is that previously we thought of the gradient as v^i(\\partial_i f) where v^i is the vector we’ve dotted into the gradient \\partial_i f. All we are doing now is reinterpretting as (v^i\\partial_i)f where the only shift in philosophy is that we now think of the linear map v^i\\partial_i acting on the function f. Thus, vectors in differential geometry survive as the directional deriviatves that they induce. However, if we know how these operators act on any function, we may apply them to the coordinate functions in particular to re-obtain our previous notion of the vector components."
  },
  {
    "objectID": "Lecture5.html#tangent-vector-space",
    "href": "Lecture5.html#tangent-vector-space",
    "title": "3  Tangent Spaces",
    "section": "3.2 Tangent Vector Space",
    "text": "3.2 Tangent Vector Space\nDefinition For each point p\\in\\mathcal{M}, we define the set T_p\\mathcal{M} as the “tangent space to \\mathcal{M} at p”, i.e.  \\begin{equation}\n    T_p\\mathcal{M} := \\left\\{ \\mathscr{v}_{\\gamma, p} | \\gamma \\text{ smooth curves through } p \\right\\}\n\\end{equation}\nPicture:\n\n\n\nFigure 3.1: Intrinsic versus extrinsic view of tangent space\n\n\nIn Figure 3.1 we see two differing realizations of the tangent space. On the left, we show the tangent space as defined above from an intrinsic standpoint. On the right we see the manifold M embedded in a d+1 dimensional space so that T_p\\mathcal{M} is a literal plane. While these views are technically equivalent, we choose the intrinsic view to be aesthetically superior.\nKey observation: T_p\\mathcal{M} can be equipped with a vector space structure. Immediately, we can add two elements from T_p\\mathcal{M} pointwise: \\begin{align}\n    +&:T_p\\mathcal{M}\\times T_p\\mathcal{M} \\to  \\text{Hom}(C^{\\infty}(\\mathcal{M}), \\mathbb{R})\\\\\n    (\\mathscr{v}_{\\gamma, p} + \\mathscr{v}_{\\delta, p})(f) &:= \\mathscr{v}_{\\gamma, p}(f) +_{\\mathbb{R}} \\mathscr{v}_{\\delta, p}(f)\n\\end{align} and likewise for s-multiplication. It remains to be shown that\n\nthere actually exists a curve \\sigma such that \\mathscr{v}_{\\gamma, p} + \\mathscr{v}_{\\delta, p} = \\mathscr{v}_{\\sigma, p}\nthere actually exists a curve \\tau such that \\alpha \\mathscr{v}_{\\gamma, p} = \\mathscr{v}_{\\tau, p}\n\nIn other words, that we actually end up back in T_p\\mathcal{M}. Let’s start with the proof for s-multiplication:\nLet \\tau: \\mathbb{R}\\to\\mathcal{M} be defined such that \\begin{equation}\n    \\lambda \\mapsto \\tau(\\lambda) := \\gamma(\\alpha\\lambda + \\lambda_0) = (\\gamma \\circ \\mu_\\alpha)(\\lambda_0)\n\\end{equation} where \\begin{align}\n    \\mu_\\alpha&: \\mathbb{R} \\to \\mathbb{R} \\\\\n    r &\\mapsto \\alpha r + \\lambda_0\n\\end{align}\nWe see that \\begin{align}\n    \\tau(0) &= \\gamma(\\alpha 0 + \\lambda_0) = \\gamma(\\lambda_0) \\\\\n    \\mathscr{v}_{\\tau, p} &= (f\\circ \\tau)'(0) \\\\\n    &= (f\\circ \\gamma \\circ \\mu_\\alpha)'(0) \\\\\n    &= (f\\circ \\gamma)'(\\lambda_0)\\cdot \\alpha \\\\\n    &= \\alpha \\mathscr{v}_{\\gamma, p}\n\\end{align} where in the last line we used the chain rule.\nNext, let’s try out the sum: \\begin{align}\n    \\mathscr{v}_{\\gamma, p} + \\mathscr{v}_{\\delta, p} &= \\mathscr{v}_{\\sigma, p}\n\\end{align} We make a choice of chart (\\mathcal{U}, x)2 so that \\begin{align}\n    \\sigma&:\\mathbb{R} \\to \\mathcal{M} \\\\\n    \\sigma(\\lambda)  &:= x^{-1}\\Big( (x\\circ \\gamma)(\\lambda_0+\\lambda) + (x\\circ\\delta)(\\lambda_1 + \\lambda) - (x\\circ\\gamma)(\\lambda_0) \\Big)\n\\end{align}2 Your ill-definition alarm bells should be ringing. In the end, there should be no dependence on the choice of chart of we’ve done something wrong.\nWe claim that this does the trick. First, let’s look at \\sigma(0). We have \\begin{align}\n    \\sigma(0) &= x^{-1}\\Big( (x\\circ\\gamma)(\\lambda_0) + (x\\circ\\delta)(\\lambda_1) - (x\\circ\\gamma)(\\lambda_0)\\Big) \\\\\n    &= x^{-1}((x\\circ\\delta)(\\lambda_1)) \\\\\n    &= \\delta(p)\n\\end{align}\nso we confirmed that we hit the correct point. Now, let’s check that the velocity is correct: \\begin{align}\n    \\mathscr{v}_{\\sigma, p}(f) &= (f\\circ\\sigma)'(0) \\\\\n    &= (f\\circ x^{-1} \\circ x \\circ \\sigma)'(0) \\\\\n    &= (x^i\\circ\\sigma)'(0)\\partial_i(f\\circ x^{-1})(x(\\sigma(0))) \\\\\n    &= (x^i\\circ\\sigma)'(0)\\partial_i(f\\circ x^{-1})(x(p)) \\\\\n    &= \\Big[ (x^i\\circ \\gamma)'(\\lambda_0)+ (x^i\\circ\\delta)'(\\lambda_1)\\Big]\\partial_i(f\\circ x^{-1})(x(p)) \\\\\n    &= (x^i\\circ \\gamma)'(\\lambda_0)\\partial_i(f\\circ x^{-1})(x(p)) \\\\\n    &\\qquad + (x^i\\circ\\delta)'(\\lambda_1)\\partial_i(f\\circ x^{-1})(x(p))  \\\\\n    &= (f\\circ\\gamma)'(\\lambda_0) + (f\\circ\\delta)'(\\lambda_1) \\\\\n    &= \\mathscr{v}_{\\gamma, p}(f) + \\mathscr{v}_{\\delta, p}(f)\n\\end{align}\nNow we can confirm that the addition and s-multiplication on T_p\\mathcal{M} do close thus proving that T_p\\mathcal{M} is, in fact, a vector space."
  },
  {
    "objectID": "Lecture5.html#components-of-a-vector-with-respect-to-a-chart",
    "href": "Lecture5.html#components-of-a-vector-with-respect-to-a-chart",
    "title": "3  Tangent Spaces",
    "section": "3.3 Components of a Vector with respect to a Chart",
    "text": "3.3 Components of a Vector with respect to a Chart\nDefinition: Let (\\mathcal{U}, x)\\in \\mathscr{A}. Let \\gamma:\\mathbb{R}\\to\\mathcal{M} be a curve with \\gamma(0)=p. Then 3 \\begin{align}\n    \\mathscr{v}_{\\gamma, p}(f) &= (f\\circ \\gamma)'(0) \\\\\n        &= (f\\circ x^{-1} \\circ x \\circ \\gamma)'(0) \\\\\n        &= (x^i\\circ\\gamma)'(0)\\partial_i(f\\circ x^{-1})(x(p))\n\\end{align}3 This formula appears frequently enough that it’s worth memorizing.\nBecause the term is very cumbersome, we use the notation \\begin{equation}\n    \\partial_i(f\\circ x^{-1})(x(p)) =: \\left[\\frac{\\partial f}{\\partial x^i}\\right]_p\n\\end{equation} This is not a standard partial derivative, but behaves the same. Note that f:\\mathcal{M}\\to\\mathbb{R} is a function of the manifold for which we don’t have a notion of the partial derivative.\nThe first piece, we may rewrite as \\begin{equation}\n    (x^i\\circ \\gamma)(0) =: \\dot\\gamma_x^i(0)\n\\end{equation} so that \\begin{equation}\n    \\mathscr{v}_{\\gamma, p}(f) = \\dot\\gamma_x^i(0)\\left( \\frac{\\partial}{\\partial x^i}\\right)_p f\n\\end{equation} Since this is true for all f\\in C^{\\infty}(\\mathcal{M}) then in a chart we may understand this as the velocity vector \\begin{equation}\n    \\vartheta_{\\gamma, p} := \\dot\\gamma_x^i(0)\\left(\\frac{\\partial}{\\partial x^i}\\right)_p\n\\end{equation}\nwhere we think of \\left(\\dfrac{\\partial}{\\partial x^i}\\right)_p as the chart-induced-basis of T_p\\mathcal{M}."
  },
  {
    "objectID": "Lecture5.html#chart-induced-basis",
    "href": "Lecture5.html#chart-induced-basis",
    "title": "3  Tangent Spaces",
    "section": "3.4 Chart-Induced Basis",
    "text": "3.4 Chart-Induced Basis\nDefinition: If (\\mathcal{U}, x)\\in\\mathscr{A}, then \\begin{equation}\n    \\left(\\frac{\\partial}{\\partial x^1} \\right)_p, \\left(\\frac{\\partial}{\\partial x^2} \\right)_p, ..., \\left(\\frac{\\partial}{\\partial x^d} \\right)_p, \\in T_p\\mathcal{M}\n\\end{equation} constitute a basis for T_p\\mathcal{U}.\nTo show linear independence, we apply the ith vector to the jth component function\n\\begin{align}\n    0 = \\lambda^i\\frac{\\partial}{\\partial x^i} (x^j)\n    &= \\lambda^i\\partial_i(x^j\\circ x^{-1})(x(p)) \\\\\n    &= \\lambda^i \\delta^j_i \\\\\n    &= \\lambda^j\n\\end{align} Thus, these really do constitute a basis.\nA corollary of this is that the dimension of T_p\\mathcal{M} is \\text{dim}(\\mathcal{M})."
  },
  {
    "objectID": "Lecture5.html#change-of-cector-components-under-a-change-of-chart",
    "href": "Lecture5.html#change-of-cector-components-under-a-change-of-chart",
    "title": "3  Tangent Spaces",
    "section": "3.5 Change of Cector Components under a Change of Chart",
    "text": "3.5 Change of Cector Components under a Change of Chart\nNOTE: A tangent vector does not change because you decide to use a different chart. The components change.\nTerminology: We will now write X\\in T_p\\mathcal{M} instead of the more cumbersome curve notation. We also may write \\begin{equation}\n    X = X^i\\left(\\frac{\\partial}{\\partial x^i} \\right)_p\n\\end{equation}\nLet (\\mathcal{U}, x), (\\mathcal{V}, y) be overlapping charts with p\\in\\mathcal{U}\\cap\\mathcal{V}. Let X\\in T_p\\mathcal{M}. Then \\begin{align}\n    X &= X_{(x)}^i \\left(\\frac{\\partial}{\\partial x^i}\\right)  = X_{(y)}^i\\left(\\frac{\\partial}{\\partial y^i}\\right)_p\\\\\n\\end{align} consider the following: \\begin{align}\n    \\frac{\\partial}{\\partial x^i}f &= \\partial_i(f\\circ x^{-1})(x(p)) \\\\\n        &= \\partial_i \\left( f \\circ y^{-1} \\circ y \\circ x^{-1}\\right)(x(p)) \\\\\n        &= \\partial_i(y^j \\circ x^{-1})(x(p)) \\cdot \\partial_j(f\\circ y^{-1})(y(p)) \\\\\n        &= \\frac{\\partial y^j}{\\partial x^i}\\cdot \\frac{\\partial f}{\\partial y^j} \\\\\n        &= \\left(\\frac{\\partial y^j}{\\partial x^i}\\right)\\cdot \\left(\\frac{\\partial }{\\partial y^j}\\right) f\\\\\n\\end{align}\nTherefore, insertion into the previous equation yields \\begin{align}\n    X_{x}^i \\frac{\\partial y^j}{\\partial x^i}\\frac{\\partial}{\\partial y^j}  &= X_{(y)}^j\\frac{\\partial}{\\partial y^j} \\\\\n    X_{(y)}^j &= \\left(\\frac{\\partial y^j}{\\partial x^i} \\right) X_{(x)}^i\n\\end{align} which is exactly the transformation law for the components of a tangent vector X when we switch between two charts with coordinate functions x^i and y^j."
  },
  {
    "objectID": "Lecture5.html#cotangent-spaces",
    "href": "Lecture5.html#cotangent-spaces",
    "title": "3  Tangent Spaces",
    "section": "3.6 Cotangent Spaces",
    "text": "3.6 Cotangent Spaces\nGiven that we have T_p\\mathcal{M}, it is natural to consider (T_p\\mathcal{M})^*, i.e. the dual to the tangent space: \\begin{equation}\n    (T_p\\mathcal{M})^* := \\left\\{\\phi: T_p\\mathcal{M}\\xrightarrow{\\sim} \\mathbb{R} \\right\\}\n\\end{equation}\nExample: Consider f\\in C^{\\infty}(\\mathcal{M}). Then \\begin{align}\n    (df)_p &:  T_p\\mathcal{M} \\xrightarrow{\\sim} \\mathbb{R} \\\\\n      X &\\mapsto (df)_p(X) := Xf\n\\end{align}\ni.e. (df)_p\\in(T_p\\mathcal{M})^*! This is called the gradient of f at p\\in\\mathcal{M}.\nFurther, we can calculate the components of the gradient… \\begin{align}\n    \\left((df)_p\\right)_j &:= (df)_p \\left(\\frac{\\partial }{\\partial x_j}\\right)_p \\\\\n    &= \\left( \\frac{\\partial f}{\\partial x^j} \\right)_p\n\\end{align}\nUpshot: The gradient of a function is not a vector, it’s a covector!\nTheorem: Consider the chart (\\mathcal{U}, x) so that we have coordinate maps x^i:\\mathcal{U}\\to\\mathbb{R}. The claim is \\begin{equation}\n    (d x^1)_p, (d x^2)_p, ..., (d x^d)_p\n\\end{equation} is the dual basis for T_p^*\\mathcal{M}. Observe: \\begin{align}\n    (d x^a)_p(\\frac{\\partial }{\\partial x^b}) = \\frac{\\partial x^a}{\\partial x^b} = \\delta_b^a\n\\end{align}"
  },
  {
    "objectID": "Lecture5.html#change-of-components-of-a-covector-with-respect-to-a-change-of-chart.",
    "href": "Lecture5.html#change-of-components-of-a-covector-with-respect-to-a-change-of-chart.",
    "title": "3  Tangent Spaces",
    "section": "3.7 Change of components of a covector with respect to a change of chart.",
    "text": "3.7 Change of components of a covector with respect to a change of chart.\nLet \\omega \\in T_p^*\\mathcal{M}, then \\begin{align}\n    \\omega_{(y)j}(dy^j)_p &= \\omega = \\omega_{(x)i} (dx^i)_p \\\\\n    \\Rightarrow \\omega_{(y)i} &= \\frac{\\partial x^j}{\\partial y^i}\\omega_{(x)j}\n\\end{align} 44 In the tutorial session, we will show that \\frac{\\partial x^i}{\\partial y^j} is the matrix inverse to \\frac{\\partial y^m}{\\partial x^n}"
  },
  {
    "objectID": "Lecture6.html",
    "href": "Lecture6.html",
    "title": "4  Fields",
    "section": "",
    "text": "So far we’ve focused on the tangent space (and its dual) at a single point p\\in\\mathcal{M}. As physicists, we are interested in vector fields, i.e. a vector at every point in space. The rigorous way to do this is the Theory of Bundles. So, we develope it…"
  },
  {
    "objectID": "Lecture6.html#bundles",
    "href": "Lecture6.html#bundles",
    "title": "4  Fields",
    "section": "4.1 Bundles",
    "text": "4.1 Bundles\nDefinition: A bundle is a triple E\\xrightarrow{\\pi}M where\n\nE is a smooth manifold called the total space\n\\pi:E\\to M is the smooth, surjective projection map\nM is a smooth manifold called the base space\n\nAny 3 pieces of data like this are called a bundle.\n\n4.1.1 Example: The cylinder\nWe can think of E as a cylinder, M as a circle, and \\pi chosen to to project the point on the cylinder vertically down to z=0 on the circle. See $fig-cylinderbundle\n\n\n\n\n\nFigure 4.1: The Cylinder interpreted as a bundle\n\n\nDefinition: Given a bundle (E,\\pi, M), we define the fibre over p as \\text{preim}_\\pi(\\{p \\})\nDefinition: A section \\sigma is a map \\sigma:M\\to E (i.e. this goes the other way!) with the requirement that \\begin{equation}\n    \\pi \\circ \\sigma = \\text{Id}_M\n\\end{equation}\nAs physicists now, we may consider our manifold \\mathcal{M} where the fibres over each p\\in\\mathcal{M} are just T_p\\mathcal{M}. What would the sections be? A section here would be a map that gives a vector for every point p\\in\\mathcal{M}. This is exactly what we think of when we think of vector fields.\nSummary: The sections are our physics notion of fields. The type of field is determined by the type of fibre. 1Note: here we have extended the action of a vector at a point on a function to the action of a vector field on a manifold in the obvious way, i.e.\n\\begin{aligned}\n&\\chi f: \\mathcal{M} \\to \\mathbb{R} \\\\\n&p \\mapsto \\chi(p)f\n\\end{aligned}\n\nThe natual next question is what is the total space we are thinking of? Can we collect each T_p\\mathcal{M} into a smooth manifold?"
  },
  {
    "objectID": "Lecture6.html#tangent",
    "href": "Lecture6.html#tangent",
    "title": "4  Fields",
    "section": "4.2 Tangent",
    "text": "4.2 Tangent"
  },
  {
    "objectID": "Lecture6.html#tangent-bundle",
    "href": "Lecture6.html#tangent-bundle",
    "title": "4  Fields",
    "section": "4.2 Tangent Bundle",
    "text": "4.2 Tangent Bundle"
  },
  {
    "objectID": "Lecture6.html#tangent-bundle-of-a-smooth-manifold",
    "href": "Lecture6.html#tangent-bundle-of-a-smooth-manifold",
    "title": "4  Fields",
    "section": "4.2 Tangent Bundle of a Smooth Manifold",
    "text": "4.2 Tangent Bundle of a Smooth Manifold\nLet (\\mathcal{M}, \\mathcal{O}, \\mathscr{A}) be a smooth manifold. We define the Tangent Bundle\n\nas a set, it is the disjoint union of tangent spaces: \\begin{equation}\nT\\mathcal{M} := \\bigcup\\limits_{p\\in \\mathcal{M}}^\\bullet T_p\\mathcal{M}\n\\end{equation}\nThe surjective projection map is \\pi:T\\mathcal{M} \\to \\mathcal{M} with \\begin{equation}\nX \\mapsto p\n\\end{equation}\n\nAt this point we need to turn T\\mathcal{M} into a smooth manifold. First we make T\\mathcal{M} into a topological manifold by equipping it with a topology. Since we already have a topology on \\mathcal{M} what we do is to construct a topology on T\\mathcal{M} that is the coarsest possible topology such that \\pi becomes continuous, i.e. the initial topology with respect to \\pi: \\begin{equation}\n    \\mathcal{O}_{T\\mathcal{M}} := \\left\\{ \\text{preim}_\\pi(\\mathcal{U}) \\Big\\vert \\mathcal{U}\\in\\mathcal{O}_\\mathcal{M}\\right\\}\n\\end{equation} This makes sense as we definitly want \\pi to be continuous and therefor it must map open sets to open sets.\nNow we construct a C^{\\infty} atlas on T\\mathcal{M} from \\mathscr{A} we already have on \\mathcal{M}. \\begin{equation}\n    \\mathscr{A}_{T\\mathcal{M}} := \\left\\{ (T\\mathcal{U}, \\xi_x) \\Big\\vert (\\mathcal{U}, x)\\in \\mathscr{A} \\right\\}\n\\end{equation} where2 \\begin{align}\n    \\xi_x&: T\\mathcal{U} \\to \\mathbb{R}^{2\\text{ dim}\\mathcal{M}} \\\\\n    X &\\mapsto \\left( (x^1\\circ \\pi)(X), ... , (x^d\\circ\\pi)(X), (dx^1)_{\\pi(x)}(X), ..., (dx^d)_{\\pi(x)}(X) \\right)\n\\end{align}2 We do not mean s-multiplication here. We can multiply by any g\\in C^{\\infty}(\\mathcal{M}) since we can define the multiplication pointwise using multiplication in \\mathbb{R}.\nFurther, we may consider the inverse of the chartmap \\begin{align}\n    \\xi_x^{-1}&: \\xi_x(T\\mathcal{U}) \\to T\\mathcal{U} \\\\\n    (\\alpha^1,...\\alpha^d, \\beta^1, ... \\beta^d) &:= \\beta^i\\left(\\dfrac{\\partial}{\\partial x^i}\\right)_{x^{-1}(\\alpha^1, ..., \\alpha^d)}\n\\end{align}\nNow we must ask: are these chart maps smooth?\n\\begin{align}\n    &(\\xi_y\\circ\\xi_x^{-1})(\\alpha^1,...\\alpha^d,\\beta^1,...,\\beta^d) = \\xi_y\\left(\\beta^i\\left(\\dfrac{\\partial}{\\partial x^i}\\right)_{x^{-1}(\\alpha^1, ..., \\alpha^d)}\\right)\\\\\n&\\qquad = \\Big(..., (y^i\\circ\\pi)\\left(\\beta^n\\left(\\dfrac{\\partial}{\\partial x^n}\\right)_{x^{-1}(\\alpha^1, ..., \\alpha^d)}\\right),..., \\\\\n&\\qquad\\qquad ...,(dy^i)_{x^{-1}(\\alpha^1,...\\alpha^d)}\\left(\\beta^n\\left(\\dfrac{\\partial}{\\partial x^n}\\right)_{x^{-1}(\\alpha^1, ... , \\alpha^d)}\\right) ,... \\Big) \\\\\n&\\qquad = \\left(..., (y^i\\circ x^{-1})(\\alpha^1,...,\\alpha^d),..., ...,\\beta^n dy^i\\left(\\frac{\\partial}{\\partial x^n}\\right) , ... \\right) \\\\\n&\\qquad = \\left(..., (y^i\\circ x^{-1})(\\alpha^1,...,\\alpha^d),..., ...,\\beta^n \\left(\\frac{\\partial y^i}{\\partial x^n}\\right) , ... \\right) \\\\\n\\end{align} Is this a smooth map? Yes, because the chart transition map y^i\\circ x^{-1} are smooth and so are the change of coordinate functions \\frac{\\partial y^i}{\\partial x^j}.\nThus, we can conclude that (T\\mathcal{M}, \\pi, \\mathcal{M}) really is a bundle which we call the Tangent bundle"
  },
  {
    "objectID": "Lecture6.html#vector-fields",
    "href": "Lecture6.html#vector-fields",
    "title": "4  Fields",
    "section": "4.3 Vector Fields",
    "text": "4.3 Vector Fields\nDefinition: A smooth vector field \\chi is a smooth section of the tangent bundle (T\\mathcal{M}, \\pi, \\mathcal{M}), i.e.  \\begin{align}\n    &\\chi:\\mathcal{M}\\to T\\mathcal{M} \\\\\n    &\\pi\\circ\\chi = \\text{Id}_\\mathcal{M}\n\\end{align}"
  },
  {
    "objectID": "Lecture6.html#the-cinftymathcalm-module-gammatmathcalm",
    "href": "Lecture6.html#the-cinftymathcalm-module-gammatmathcalm",
    "title": "4  Fields",
    "section": "4.4 The C^{\\infty}(\\mathcal{M})-module \\Gamma(T\\mathcal{M})",
    "text": "4.4 The C^{\\infty}(\\mathcal{M})-module \\Gamma(T\\mathcal{M})\nDefinition: We define \\Gamma(T\\mathcal{M}) as \\begin{equation}\n    \\Gamma(T\\mathcal{M}) = \\left\\{ \\chi:T\\mathcal{M}\\to\\mathcal{M}\\Big\\vert \\text{ smooth section } \\right\\}\n\\end{equation} which we equip with addition by3 \\begin{equation}\n    (\\chi + \\tilde\\chi)(f) := \\chi f + \\tilde\\chi f\n\\end{equation}Note: here we have extended the action of a vector at a point on a function to the action of a vector field on a manifold in the obvious way, i.e.\n\\begin{aligned}\n&\\chi f: \\mathcal{M} \\to \\mathbb{R} \\\\\n&p \\mapsto \\chi(p)f\n\\end{aligned}\n\nas well as multiplication4 via\n4 We do not mean s-multiplication here. We can multiply by any g\\in C^{\\infty}(\\mathcal{M}) since we can define the multiplication pointwise using multiplication in \\mathbb{R}.\\begin{aligned}\n    (g\\cdot \\chi)(f) := g\\cdot \\chi(f)\n\\end{aligned}\nThe special case of a vector field over the ring is called a module.\nUpshot: The set of all smooth vector fields can be made into a C^{\\infty}(\\mathcal{M})-module.\nWe can now use \\frac{\\partial}{\\partial x^i}:\\mathcal{U}\\to T\\mathcal{U} with no supscript for the point to denote the coordinate induced vector field."
  },
  {
    "objectID": "Lecture6.html#tensor-fields",
    "href": "Lecture6.html#tensor-fields",
    "title": "4  Fields",
    "section": "4.5 Tensor Fields",
    "text": "4.5 Tensor Fields\nIn much the same way as we constructed \\Gamma(T\\mathcal{M}), we can define the cotangent fields via \\Gamma(T^*\\mathcal{M}) using the cotangent bundle (T^*\\mathcal{M}, \\pi, \\mathcal{M}). With these two objects in hand, we proceed to tensor fields.\nDefinition: An (r,s)-tensor field T is a C^{\\infty}(\\mathcal{M})-multi-linear map \\begin{equation}\n    T: \\Gamma(T^*\\mathcal{M})\\times \\underset{r}{...}\\times  \\Gamma(T^*\\mathcal{M})\\times  \\Gamma(T^\\mathcal{M})\\underset{s}{...}\\times \\Gamma(T^\\mathcal{M}) \\xrightarrow{\\sim} C^{\\infty}(\\mathcal{M})\n\\end{equation}\n\n4.5.1 Example\nFor any f\\in C^{\\infty}(\\mathcal{M}), we define \\begin{align}\n    &df : \\gamma(T\\mathcal{M}) \\xrightarrow{\\sim} C^{\\infty}(\\mathcal{M}) \\\\\n    &\\chi \\mapsto df(\\chi)\n\\end{align} where (\\chi f)(p) = \\chi(p)f."
  }
]